{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a826acc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch.nn.functional as F\n",
    "import json\n",
    "import gc\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from lightning import Fabric\n",
    "\n",
    "from huggingface_hub import login\n",
    "from transformers import get_scheduler, pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig, TrainingArguments, Trainer, EarlyStoppingCallback\n",
    "from peft import get_peft_model, LoraConfig, TaskType, PeftModelForCausalLM\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from pprint import pprint\n",
    "from tqdm import tqdm\n",
    "# import warnings\n",
    "# warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "%config InlineBackend.figure_formats = ['svg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f204e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/train_test_data.json', 'r', encoding='utf-8') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8c5624d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "fabric = Fabric(accelerator=\"cuda\", devices=1, precision=\"bf16-mixed\")\n",
    "device = fabric.device\n",
    "fabric.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378dc3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# teacher_model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "student_model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True,\n",
    ")\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\"],\n",
    "    lora_dropout=0.2,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "# teacher = AutoModelForCausalLM.from_pretrained(teacher_model_name, device_map=\"auto\", quantization_config=quant_config,).eval()\n",
    "student_model = AutoModelForCausalLM.from_pretrained(student_model_name, device_map=\"auto\", quantization_config=quant_config,).train()\n",
    "tokenizer = AutoTokenizer.from_pretrained(student_model_name)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
