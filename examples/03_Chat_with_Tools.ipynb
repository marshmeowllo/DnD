{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ea2803",
   "metadata": {},
   "source": [
    "# Chat With Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29071199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import uuid\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from peft import PeftModel, LoraConfig\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings, ChatHuggingFace\n",
    "from langchain.tools import tool\n",
    "\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from langchain_core.messages import SystemMessage, AnyMessage\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.runnables import RunnableConfig, Runnable\n",
    "from langchain_core.tools import BaseTool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "\n",
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "\n",
    "from typing import Annotated, Any, Dict, Optional, TypedDict, Union, List\n",
    "from lightning import Fabric\n",
    "\n",
    "from IPython.display import display, Markdown, Image, SVG\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd806861",
   "metadata": {},
   "source": [
    "### Set mixed precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2463854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "fabric = Fabric(accelerator=\"cuda\", devices=1, precision=\"bf16-mixed\")\n",
    "device = fabric.device\n",
    "fabric.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc9f613",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a52614d3",
   "metadata": {},
   "source": [
    "### Load Embedding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "51f3676e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embed_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9100489",
   "metadata": {},
   "source": [
    "### Load vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f30b2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.load_local(\n",
    "    \"./faiss_dnd_index\",\n",
    "    embeddings=embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf13e68",
   "metadata": {},
   "source": [
    "### Mock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1000e2fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "      <th>email</th>\n",
       "      <th>num_posts</th>\n",
       "      <th>num_likes</th>\n",
       "      <th>num_followers</th>\n",
       "      <th>num_following</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>user_1</td>\n",
       "      <td>User1</td>\n",
       "      <td>30</td>\n",
       "      <td>user1@example.com</td>\n",
       "      <td>311</td>\n",
       "      <td>7777</td>\n",
       "      <td>37874</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user_2</td>\n",
       "      <td>User2</td>\n",
       "      <td>57</td>\n",
       "      <td>user2@example.com</td>\n",
       "      <td>380</td>\n",
       "      <td>4590</td>\n",
       "      <td>56551</td>\n",
       "      <td>3237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user_3</td>\n",
       "      <td>User3</td>\n",
       "      <td>57</td>\n",
       "      <td>user3@example.com</td>\n",
       "      <td>46</td>\n",
       "      <td>8255</td>\n",
       "      <td>1651</td>\n",
       "      <td>2249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>user_4</td>\n",
       "      <td>User4</td>\n",
       "      <td>50</td>\n",
       "      <td>user4@example.com</td>\n",
       "      <td>122</td>\n",
       "      <td>3045</td>\n",
       "      <td>57246</td>\n",
       "      <td>3679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>user_5</td>\n",
       "      <td>User5</td>\n",
       "      <td>25</td>\n",
       "      <td>user5@example.com</td>\n",
       "      <td>421</td>\n",
       "      <td>1078</td>\n",
       "      <td>85481</td>\n",
       "      <td>3883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>user_6</td>\n",
       "      <td>User6</td>\n",
       "      <td>32</td>\n",
       "      <td>user6@example.com</td>\n",
       "      <td>470</td>\n",
       "      <td>7942</td>\n",
       "      <td>97368</td>\n",
       "      <td>2791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>user_7</td>\n",
       "      <td>User7</td>\n",
       "      <td>47</td>\n",
       "      <td>user7@example.com</td>\n",
       "      <td>455</td>\n",
       "      <td>96</td>\n",
       "      <td>17072</td>\n",
       "      <td>1573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>user_8</td>\n",
       "      <td>User8</td>\n",
       "      <td>48</td>\n",
       "      <td>user8@example.com</td>\n",
       "      <td>2</td>\n",
       "      <td>5761</td>\n",
       "      <td>41789</td>\n",
       "      <td>3019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>user_9</td>\n",
       "      <td>User9</td>\n",
       "      <td>18</td>\n",
       "      <td>user9@example.com</td>\n",
       "      <td>228</td>\n",
       "      <td>1958</td>\n",
       "      <td>33844</td>\n",
       "      <td>4538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>user_10</td>\n",
       "      <td>User10</td>\n",
       "      <td>53</td>\n",
       "      <td>user10@example.com</td>\n",
       "      <td>155</td>\n",
       "      <td>9690</td>\n",
       "      <td>23873</td>\n",
       "      <td>3086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id    name  age               email  num_posts  num_likes  \\\n",
       "0   user_1   User1   30   user1@example.com        311       7777   \n",
       "1   user_2   User2   57   user2@example.com        380       4590   \n",
       "2   user_3   User3   57   user3@example.com         46       8255   \n",
       "3   user_4   User4   50   user4@example.com        122       3045   \n",
       "4   user_5   User5   25   user5@example.com        421       1078   \n",
       "5   user_6   User6   32   user6@example.com        470       7942   \n",
       "6   user_7   User7   47   user7@example.com        455         96   \n",
       "7   user_8   User8   48   user8@example.com          2       5761   \n",
       "8   user_9   User9   18   user9@example.com        228       1958   \n",
       "9  user_10  User10   53  user10@example.com        155       9690   \n",
       "\n",
       "   num_followers  num_following  \n",
       "0          37874            202  \n",
       "1          56551           3237  \n",
       "2           1651           2249  \n",
       "3          57246           3679  \n",
       "4          85481           3883  \n",
       "5          97368           2791  \n",
       "6          17072           1573  \n",
       "7          41789           3019  \n",
       "8          33844           4538  \n",
       "9          23873           3086  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_users = 10\n",
    "\n",
    "data = {\n",
    "    \"user_id\": [f\"user_{i+1}\" for i in range(n_users)],\n",
    "    \"name\": [f\"User{i+1}\" for i in range(n_users)],\n",
    "    \"age\": np.random.randint(18, 60, size=n_users),\n",
    "    \"email\": [f\"user{i+1}@example.com\" for i in range(n_users)],\n",
    "    \"num_posts\": np.random.randint(0, 500, size=n_users),\n",
    "    \"num_likes\": np.random.randint(0, 10000, size=n_users),\n",
    "    \"num_followers\": np.random.randint(0, 100000, size=n_users),\n",
    "    \"num_following\": np.random.randint(0, 5000, size=n_users),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2efde47",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd857be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def spell_retrieve(query: str) -> str:\n",
    "    \"\"\"Retrieve information about dungeons and dragons spell.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The spell name to search for.\n",
    "\n",
    "    Returns:\n",
    "        str: The spell information.\n",
    "    \"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=3)\n",
    "\n",
    "    contents = \"\\n\\n\".join(\n",
    "        (f\"{doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    \n",
    "    return contents\n",
    "\n",
    "@tool\n",
    "def user(name: str) -> str:\n",
    "    \"\"\"\n",
    "    User infomation retreiver\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of user.\n",
    "\n",
    "    Returns:\n",
    "        str: The user information.\n",
    "    \"\"\"\n",
    "    return f'{df[df['name'] == name]}.'\n",
    "\n",
    "tools = [\n",
    "    spell_retrieve,\n",
    "    user\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bb85cf",
   "metadata": {},
   "source": [
    "## Workflow\n",
    "\n",
    "```\n",
    "[User Message] \n",
    "     ↓\n",
    "[xLAM-2] → [Check if Tool Call is Required] \n",
    "     ├── No → [Return to Llama 3 with \"No tool needed\"]\n",
    "     └── Yes → [Detect Tool to Call] → [Prepare Structured Tool Call] → [Execute Tool] → [Send Result to Llama 3]\n",
    "                          ↓\n",
    "               [Llama 3] → [Generate Final Natural Reply]\n",
    "     ↓\n",
    "[Final reply to User]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5e4861",
   "metadata": {},
   "source": [
    "## Custom Sate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "53a248c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    name: str\n",
    "    stat: str\n",
    "    messages: Annotated[list[AnyMessage], add_messages]\n",
    "    context: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905fe375",
   "metadata": {},
   "source": [
    "## Tool Calling Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af54df93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCallRequest(TypedDict):\n",
    "    \"\"\"A typed dict that shows the inputs into the invoke_tool function.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    arguments: Dict[str, Any]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "909ac8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCalling():\n",
    "    def __init__(self, model_name: str, tools: list[BaseTool]):\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, device_map=\"cpu\")\n",
    "        self.pipe = pipeline(\n",
    "            task=\"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            return_full_text=False,\n",
    "            max_new_tokens=512,\n",
    "            top_k=10,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        self._llm = HuggingFacePipeline(pipeline=self.pipe)\n",
    "        self.chat = ChatHuggingFace(llm=self._llm, tokenizer=self.tokenizer)\n",
    "        self.rendered_tools = [convert_to_openai_tool(f) for f in tools]\n",
    "\n",
    "    def invoke_tool(\n",
    "            self,\n",
    "            tool_call_request: Union[ToolCallRequest, List[ToolCallRequest]], \n",
    "            config: Optional[RunnableConfig] = None\n",
    "    ):\n",
    "        \"\"\"A function that we can use the perform a tool invocation.\n",
    "\n",
    "        Args:\n",
    "            tool_call_request: a dict that contains the keys name and arguments.\n",
    "                The name must match the name of a tool that exists.\n",
    "                The arguments are the arguments to that tool.\n",
    "            config: This is configuration information that LangChain uses that contains\n",
    "                things like callbacks, metadata, etc.See LCEL documentation about RunnableConfig.\n",
    "\n",
    "        Returns:\n",
    "            output from the requested tool\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Tool call request:\", tool_call_request)\n",
    "        \n",
    "        # Sometimes the model outputs a list of tool call requests, \n",
    "        # so I loop each tool call and append to list\n",
    "        \n",
    "        if isinstance(tool_call_request, list):\n",
    "            output = list()\n",
    "\n",
    "            for tool_call in tool_call_request:\n",
    "                tool_name_to_tool = {tool.name: tool for tool in tools}\n",
    "                name = tool_call[\"name\"]\n",
    "                requested_tool = tool_name_to_tool[name]\n",
    "                output.append(requested_tool.invoke(tool_call[\"arguments\"], config=config))\n",
    "            return output\n",
    "        \n",
    "        tool_name_to_tool = {tool.name: tool for tool in tools}\n",
    "        name = tool_call_request[\"name\"]\n",
    "        requested_tool = tool_name_to_tool[name]\n",
    "        return requested_tool.invoke(tool_call_request[\"arguments\"], config=config)\n",
    "    \n",
    "    def invoke(self, state: State) -> List[str]:\n",
    "        system_prompt = SystemMessage(f\"\"\"\\\n",
    "        You are an assistant that has access to the following set of tools. \n",
    "        Here are the names and descriptions for each tool:\n",
    "\n",
    "        {self.rendered_tools}\n",
    "\n",
    "        Given the user input, return the name and input of the tool to use. \n",
    "        Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
    "\n",
    "        The `arguments` should be a dictionary, with keys corresponding \n",
    "        to the argument names and the values corresponding to the requested values.\n",
    "        \"\"\")\n",
    "\n",
    "        chain = self.chat | JsonOutputParser() | self.invoke_tool\n",
    "        messages = [system_prompt] + [state['messages'][-1]]\n",
    "\n",
    "        try:\n",
    "            response = chain.invoke(messages)\n",
    "        except Exception as e:\n",
    "            print(\"Error invoking tool:\", e)\n",
    "            response = [\"No tool needed\"]\n",
    "\n",
    "        if not response:\n",
    "            response = [\"No tool needed\"]\n",
    "        \n",
    "        return {\"context\": AIMessage(response)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ece929",
   "metadata": {},
   "source": [
    "### ToolCalling Class Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "83203c87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "715b9ed820614469a790915cda89b3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "tool_calling_model_name = \"Salesforce/Llama-xLAM-2-8b-fc-r\"\n",
    "\n",
    "tool_calling = ToolCalling(\n",
    "    model_name=tool_calling_model_name,\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a07f6b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tool(state: State) -> str:\n",
    "    return tool_calling.invoke(state)\n",
    "\n",
    "graph = StateGraph(State)\n",
    "graph.add_edge(START, \"tool call\")\n",
    "graph.add_node(\"tool call\", tool)\n",
    "graph.add_edge(\"tool call\", END)\n",
    "\n",
    "graph = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b53bdc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\"],\n",
    "    lora_dropout=0.2,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60520439",
   "metadata": {},
   "source": [
    "## Llama-3 Chat Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a0b8be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LlamaChat():\n",
    "    def __init__(self, model_name: str):\n",
    "        self.model_name = model_name\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, load_in_4bit=True)\n",
    "        self.adapter_model_name = './weights/bestRL_SFT'\n",
    "        self.model = PeftModel.from_pretrained(self.model, self.adapter_model_name)\n",
    "        self.model = self.model.merge_and_unload()\n",
    "        self.pipe = pipeline(\n",
    "            task=\"text-generation\",\n",
    "            model=self.model,\n",
    "            tokenizer=self.tokenizer,\n",
    "            return_full_text=False,\n",
    "            max_new_tokens=2048,\n",
    "            top_k=10,\n",
    "            device_map=\"auto\"\n",
    "        )\n",
    "        self._llm = HuggingFacePipeline(pipeline=self.pipe)\n",
    "        self.chat = ChatHuggingFace(llm=self._llm, tokenizer=self.tokenizer)\n",
    "\n",
    "    def generate(self, state: State) -> Dict[str, Any]:\n",
    "        system_message_content = (\n",
    "            \"<|begin_of_text|>\\n\"\n",
    "            \"<|start_header_id|>system<|end_header_id|>\\n\"\n",
    "            \"You are a highly skilled Dungeon Master (DM) for Dungeons & Dragons 5th Edition. \"\n",
    "            \"Your job is to read the player’s input and reply with an immersive, clear, and engaging narration that advances the story and game mechanics.\\n\"\n",
    "            \"\\n\"\n",
    "            # \"Advice for the DM:\\n\"\n",
    "            # \"  - Describe scenes with vivid sensory details and atmosphere.\\n\"\n",
    "            # \"  - Offer meaningful choices if players ask for choices; respect player agency and avoid railroading.\\n\"\n",
    "            # \"  - Keep secret die rolls hidden; reveal only the results and their effects.\\n\"\n",
    "            # \"  - Use rules faithfully but prioritize fun and pacing over strict book-keeping.\\n\"\n",
    "            # \"  - Improvise when players surprise you, but maintain internal consistency.\\n\"\n",
    "            # \"  - Avoid technical jargon in your narration—stay in character and tone.\\n\"\n",
    "            # \"\\n\"\n",
    "            \"Basic D&D 5e Rules Summary:\\n\"\n",
    "            \"  - Initiative: roll a d20 + Dexterity modifier to determine turn order.\\n\"\n",
    "            \"  - Actions: on your turn you can take one Action, one Bonus Action (if available), and move up to your speed.\\n\"\n",
    "            \"  - Reactions: special actions triggered outside your turn, such as Opportunity Attacks.\\n\"\n",
    "            \"  - Advantage & Disadvantage: roll two d20s; take the higher roll for advantage or the lower for disadvantage.\\n\"\n",
    "            \"  - Spellcasting: consumes spell slots; cantrips are cast at will; concentration holds one spell at a time.\\n\\n\"\n",
    "            \"Campaign detail:\\n\"\n",
    "            \"At the heart of Barovia, a land shrouded in perpetual mist and the oppressive gloom of Castle Ravenloft looming above, the adventurers find themselves trapped within the cursed domain of Strahd.\\n\"\n",
    "            \"The infamous vampire lord Strahd von Zarovich rules with iron and blood, his tragic past entwined with dark magic and unrequited love.\\n\"\n",
    "            \"The party’s destiny is guided by a cryptic Tarokka deck reading from Madam Eva, randomizing the locations of three powerful artifacts—the Sunsword, the Tome of Strahd, and the Holy Symbol of Ravenkind—to set the stakes for their final confrontation.\\n\"\n",
    "            \"Early survival often hinges on navigating the deathly Svalich Woods, where sentient trees and wendigos prowl, and entering the perilous Death House to learn that not all horrors are undead.\\n\"\n",
    "            \"In the Village of Barovia, the PCs meet Ismark and Ireena Kolyana—siblings haunted by Strahd’s obsession—and may face a night assault in the graveyard by the vampire himself.\\n\"\n",
    "            \"As they pursue their quest, they reach Vallaki’s forced festivals of joy, unmasking Baron Vallakovich’s dark secrets beneath the town’s brittle gaiety. :\\n\"\n",
    "            \"The modular nature of the land allows for side trips to Argynvostholt’s haunted halls, Van Richten’s Tower of mad experimentation, and the haunted Ruins of Berez—each offering unique encounters like the Abbot’s twisted deva or Baba Lysaga’s creeping hut. :\\n\"\n",
    "            \"A crucial detour to the Wizard of Wines winery leads through Yester Hill, where twig blights and corrupted druids guard a dark gem needed to lift the vineyard’s curse. :\\n\"\n",
    "            \"At their journey’s culmination, the PCs storm Castle Ravenloft’s shadowed halls, confront Strahd amid gothic spires, and challenge his vampire spawn and brides in a climactic battle for Barovia’s freedom. :\\n\"\n",
    "            \"The module’s gothic ambiance is enriched by haunting music cues, Tarokka card handouts, and richly illustrated maps that deepen immersion in Barovia’s despair. :\\n\"\n",
    "            \"This is the retrieved context:\\n\\n\"\n",
    "            f\"{state['context']}\\n\\n\"\n",
    "            \"You must follow the these rules strictly\\n\\n \"\n",
    "            \"1. DO NOT simulate the result of player\\'s actions.\\n\\n\"\n",
    "            \"2.Do not include <CHARACTER>.\\n\\n\"\n",
    "            \"3.Use the context provided.\\n\\n\"\n",
    "            \"YOU MUST ALSO USE these current game state data :\"\n",
    "            \"Current location: Vallaki’s forced festivals of joy\"\n",
    "            # \"When you answer the player, you must respond in proper markdown format: heading, table, bold, italic, paragraph, blockquotes.\\n\"\n",
    "        )\n",
    "\n",
    "        print('State:', state)\n",
    "        print('Context:', state[\"context\"])\n",
    "        print('Generating response ...')\n",
    "\n",
    "        conversation_messages = [\n",
    "            message\n",
    "            for message in state[\"messages\"]\n",
    "            if message.type in (\"human\", \"system\")\n",
    "            or (message.type == \"ai\" and not message.tool_calls)\n",
    "        ]\n",
    "\n",
    "        prompt = [SystemMessage(system_message_content)] + conversation_messages\n",
    "\n",
    "        response = self.chat.invoke(prompt)\n",
    "        \n",
    "        return {\"messages\": [response]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee396ba",
   "metadata": {},
   "source": [
    "### LlamaChat Class Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c3d8fcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "339c5cecd76a4a31bf56a1205bcf9b81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuaylong/miniconda3/envs/nlp/lib/python3.12/site-packages/peft/peft_model.py:569: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.0.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.1.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.2.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.3.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.4.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.5.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.6.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.7.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.8.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.9.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.10.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.11.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.12.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.13.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.14.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.15.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.16.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.17.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.18.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.19.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.20.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.21.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.22.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.23.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.24.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.25.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.26.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.27.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.28.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.29.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.30.self_attn.v_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.q_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.k_proj.lora_magnitude_vector.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_A.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_B.default.weight', 'base_model.model.model.layers.31.self_attn.v_proj.lora_magnitude_vector.default.weight'].\n",
      "  warnings.warn(warn_message)\n",
      "/home/yuaylong/miniconda3/envs/nlp/lib/python3.12/site-packages/peft/tuners/lora/bnb.py:351: UserWarning: Merge lora module to 4-bit linear may get different generations due to rounding errors.\n",
      "  warnings.warn(\n",
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "llama_model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "\n",
    "llama = LlamaChat(model_name=llama_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ae600af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# text = \"<|start_header_id|>player_1<|end_header_id|>\\nCan I cast meteor swarm?<|eot_id|>\"\n",
    "\n",
    "# input_state = {\n",
    "#     \"name\": \"player_1\",\n",
    "#     \"messages\": [\n",
    "#         HumanMessage(content=text)\n",
    "#     ],\n",
    "#     \"context\": \"\"\n",
    "# }\n",
    "\n",
    "# response = llama.generate(state=input_state)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21519ef",
   "metadata": {},
   "source": [
    "## LangGraph Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3bf6853e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def tool(state: State):\n",
    "    return tool_calling.invoke(state)\n",
    "\n",
    "def chatbot(state: State) -> str:\n",
    "    return llama.generate(state=state)\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = StateGraph(State)\n",
    "\n",
    "graph.add_edge(START, \"tool call\")\n",
    "graph.add_node(\"tool call\", tool)\n",
    "\n",
    "graph.add_edge(\"tool call\", \"chatbot\")\n",
    "\n",
    "graph.add_node(\"chatbot\", chatbot)\n",
    "graph.add_edge(\"chatbot\", END)\n",
    "\n",
    "graph = graph.compile(checkpointer=memory)\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c77b85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call request: [{'name': 'spell_retrieve', 'arguments': {'query': 'meteor swarm'}}]\n",
      "State: {'name': 'player_1', 'messages': [HumanMessage(content='<|start_header_id|>player_3<|end_header_id|>\\nCurrently I am level 1 wizard.\\nCan I cast meteor swarm?<|eot_id|>', additional_kwargs={}, response_metadata={}, id='489af465-4af6-4d01-8ce1-3ea2deac2dfe')], 'context': AIMessage(content=[\"# Meteor Swarm\\n## Spell Name\\nMeteor Swarm  \\n![](https://static.wikia.nocookie.net/dnd-5e/images/9/99/Meteor.png/revision/latest/scale-to-width-down/225?cb=20221130233621)\\n![](https://static.wikia.nocookie.net/dnd-5e/images/9/99/Meteor.png/revision/latest/scale-to-width-down/225?cb=20221130233621)  \\nFrom Player's Handbook, page 259.\\n## Description\\n*9th-level evocation*\\n* **Casting Time:** 1 action\\n* **Range:** 1 mile\\n* **Components:** V, S\\n* **Duration:** Instantaneous\\n- **Casting Time:** 1 action\\n\\n**At Higher Levels:** When you cast this spell using a spell slot of 4th level or higher, the number of meteors created increases by two for each slot level above 3rd.\\n**At Higher Levels:**\\n## Learned By\\n* **Classes:** Sorcerer, Wizard\\n* **Subclasses:** Fighter (*Eldritch Knight*), Rogue (*Arcane Trickster*)\\n- **Classes:** Sorcerer, Wizard\\n**Classes:**\\nSorcerer\\nWizard\\n- **Subclasses:** Fighter (*Eldritch Knight*), Rogue (*Arcane Trickster*)\\n**Subclasses:**\\n*Eldritch Knight*\\nEldritch Knight\\n\\n**Components:**\\n- **Duration:** Concentration, up to 10 minutes\\n**Duration:**\\nSwarming, biting locusts fill a 20-foot-radius sphere centered on a point you choose within range. The sphere spreads around corners. The sphere remains for the duration, and its area is lightly obscured. The sphere's area is difficult terrain.\"], additional_kwargs={}, response_metadata={})}\n",
      "Context: content=[\"# Meteor Swarm\\n## Spell Name\\nMeteor Swarm  \\n![](https://static.wikia.nocookie.net/dnd-5e/images/9/99/Meteor.png/revision/latest/scale-to-width-down/225?cb=20221130233621)\\n![](https://static.wikia.nocookie.net/dnd-5e/images/9/99/Meteor.png/revision/latest/scale-to-width-down/225?cb=20221130233621)  \\nFrom Player's Handbook, page 259.\\n## Description\\n*9th-level evocation*\\n* **Casting Time:** 1 action\\n* **Range:** 1 mile\\n* **Components:** V, S\\n* **Duration:** Instantaneous\\n- **Casting Time:** 1 action\\n\\n**At Higher Levels:** When you cast this spell using a spell slot of 4th level or higher, the number of meteors created increases by two for each slot level above 3rd.\\n**At Higher Levels:**\\n## Learned By\\n* **Classes:** Sorcerer, Wizard\\n* **Subclasses:** Fighter (*Eldritch Knight*), Rogue (*Arcane Trickster*)\\n- **Classes:** Sorcerer, Wizard\\n**Classes:**\\nSorcerer\\nWizard\\n- **Subclasses:** Fighter (*Eldritch Knight*), Rogue (*Arcane Trickster*)\\n**Subclasses:**\\n*Eldritch Knight*\\nEldritch Knight\\n\\n**Components:**\\n- **Duration:** Concentration, up to 10 minutes\\n**Duration:**\\nSwarming, biting locusts fill a 20-foot-radius sphere centered on a point you choose within range. The sphere spreads around corners. The sphere remains for the duration, and its area is lightly obscured. The sphere's area is difficult terrain.\"] additional_kwargs={} response_metadata={}\n",
      "Generating response ...\n",
      "You can cast Meteor Swarm, but be aware that as a level 1 wizard, you do not have access to the spell. Meteor Swarm is a 9th-level evocation spell, which means you are still far from being able to cast it.\n",
      "\n",
      "As you browse through the dusty tomes in the Baron's library, you overhear whispers of a mysterious gathering in the town square. The townspeople seem to be preparing for the Vallaki's forced festivals of joy, but there's an undercurrent of unease in the air. The Baron's guards are on high alert, and the air is thick with the smell of roasting meats and freshly baked bread.\n",
      "\n",
      "You notice a group of traveling performers, including a juggler, a musician, and a fire dancer, setting up their acts near the town square. The crowd is growing, and the atmosphere is tense. What would you like to do?\n"
     ]
    }
   ],
   "source": [
    "thread_id = uuid.uuid4()\n",
    "config = {\"configurable\": {\"thread_id\": \"123\"}}\n",
    "\n",
    "text = \"<|start_header_id|>player_3<|end_header_id|>\\nCurrently I am level 1 wizard.\\nCan I cast meteor swarm?<|eot_id|>\"\n",
    "\n",
    "input_state = {\n",
    "    \"name\": \"player_1\",\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=text)\n",
    "    ],\n",
    "    \"context\": \"\"\n",
    "}\n",
    "\n",
    "# for step in graph.stream(\n",
    "#     input_state,\n",
    "#     config=config,\n",
    "#     stream_mode=\"values\",\n",
    "# ):\n",
    "#     step[\"messages\"][-1].pretty_print()\n",
    "\n",
    "response = graph.invoke(input_state, config)\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b49b16f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call request: [{'name': 'user', 'arguments': {'name': 'User3'}}]\n",
      "State: {'name': 'player_1', 'messages': [HumanMessage(content='<|start_header_id|>player_3<|end_header_id|>\\nCurrently I am level 1 wizard.\\nCan I cast meteor swarm?<|eot_id|>', additional_kwargs={}, response_metadata={}, id='489af465-4af6-4d01-8ce1-3ea2deac2dfe'), AIMessage(content=\"You can cast Meteor Swarm, but be aware that as a level 1 wizard, you do not have access to the spell. Meteor Swarm is a 9th-level evocation spell, which means you are still far from being able to cast it.\\n\\nAs you browse through the dusty tomes in the Baron's library, you overhear whispers of a mysterious gathering in the town square. The townspeople seem to be preparing for the Vallaki's forced festivals of joy, but there's an undercurrent of unease in the air. The Baron's guards are on high alert, and the air is thick with the smell of roasting meats and freshly baked bread.\\n\\nYou notice a group of traveling performers, including a juggler, a musician, and a fire dancer, setting up their acts near the town square. The crowd is growing, and the atmosphere is tense. What would you like to do?\", additional_kwargs={}, response_metadata={}, id='run--fe0dc82a-9e38-4a43-8f3b-74a4c8f06070-0'), HumanMessage(content='<|start_header_id|>player_3<|end_header_id|>\\nCan you give me infomation of name User3?<|eot_id|>', additional_kwargs={}, response_metadata={}, id='4ce0f2c8-810c-46cd-8835-aa26fcd339f5')], 'context': AIMessage(content=['  user_id   name  age              email  num_posts  num_likes  num_followers  \\\\\\n2  user_3  User3   57  user3@example.com         46       8255           1651   \\n\\n   num_following  \\n2           2249  .'], additional_kwargs={}, response_metadata={})}\n",
      "Context: content=['  user_id   name  age              email  num_posts  num_likes  num_followers  \\\\\\n2  user_3  User3   57  user3@example.com         46       8255           1651   \\n\\n   num_following  \\n2           2249  .'] additional_kwargs={} response_metadata={}\n",
      "Generating response ...\n",
      "You are User_3, a level 1 wizard, with an age of 57 and an email address of user3@example.com. You have made 46 posts, received 8255 likes, and have 1651 followers. You are currently following 2 people.\n",
      "\n",
      "You are in the midst of the Vallaki's forced festivals of joy in the town square. The tension is palpable, and the air is filled with the smell of roasting meats and freshly baked bread. The crowd is growing, and the traveling performers are setting up their acts.\n",
      "\n",
      "As you observe the scene, you notice a group of guardsmen eyeing you suspiciously. They seem to be watching you with an air of curiosity, and you wonder if you've attracted their attention for some reason.\n",
      "\n",
      "The festival's festivities are about to begin, and the Baron's voice booms through the speakers, announcing the start of the celebrations. The crowd erupts into cheers and applause, and the performers take their places. The juggler begins to juggle clubs, the musician starts to play a lively tune, and the fire dancer spins and leaps through the flames.\n",
      "\n",
      "What would you like to do next?\n"
     ]
    }
   ],
   "source": [
    "text = \"<|start_header_id|>player_3<|end_header_id|>\\nCan you give me infomation of name User3?<|eot_id|>\"\n",
    "\n",
    "input_state = {\n",
    "    \"name\": \"player_1\",\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=text)\n",
    "    ],\n",
    "    \"context\": \"\"\n",
    "}\n",
    "\n",
    "# for step in graph.stream(\n",
    "#     input_state,\n",
    "#     config=config,\n",
    "#     stream_mode=\"values\",\n",
    "# ):\n",
    "#     step[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "response = graph.invoke(input_state, config)\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "045ecb72",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call request: [{'name': 'user', 'arguments': {'name': 'Tsubasa'}}]\n",
      "State: {'name': 'player_1', 'messages': [HumanMessage(content='<|start_header_id|>player_3<|end_header_id|>\\nCurrently I am level 1 wizard.\\nCan I cast meteor swarm?<|eot_id|>', additional_kwargs={}, response_metadata={}, id='489af465-4af6-4d01-8ce1-3ea2deac2dfe'), AIMessage(content=\"You can cast Meteor Swarm, but be aware that as a level 1 wizard, you do not have access to the spell. Meteor Swarm is a 9th-level evocation spell, which means you are still far from being able to cast it.\\n\\nAs you browse through the dusty tomes in the Baron's library, you overhear whispers of a mysterious gathering in the town square. The townspeople seem to be preparing for the Vallaki's forced festivals of joy, but there's an undercurrent of unease in the air. The Baron's guards are on high alert, and the air is thick with the smell of roasting meats and freshly baked bread.\\n\\nYou notice a group of traveling performers, including a juggler, a musician, and a fire dancer, setting up their acts near the town square. The crowd is growing, and the atmosphere is tense. What would you like to do?\", additional_kwargs={}, response_metadata={}, id='run--fe0dc82a-9e38-4a43-8f3b-74a4c8f06070-0'), HumanMessage(content='<|start_header_id|>player_3<|end_header_id|>\\nCan you give me infomation of name User3?<|eot_id|>', additional_kwargs={}, response_metadata={}, id='4ce0f2c8-810c-46cd-8835-aa26fcd339f5'), AIMessage(content=\"You are User_3, a level 1 wizard, with an age of 57 and an email address of user3@example.com. You have made 46 posts, received 8255 likes, and have 1651 followers. You are currently following 2 people.\\n\\nYou are in the midst of the Vallaki's forced festivals of joy in the town square. The tension is palpable, and the air is filled with the smell of roasting meats and freshly baked bread. The crowd is growing, and the traveling performers are setting up their acts.\\n\\nAs you observe the scene, you notice a group of guardsmen eyeing you suspiciously. They seem to be watching you with an air of curiosity, and you wonder if you've attracted their attention for some reason.\\n\\nThe festival's festivities are about to begin, and the Baron's voice booms through the speakers, announcing the start of the celebrations. The crowd erupts into cheers and applause, and the performers take their places. The juggler begins to juggle clubs, the musician starts to play a lively tune, and the fire dancer spins and leaps through the flames.\\n\\nWhat would you like to do next?\", additional_kwargs={}, response_metadata={}, id='run--b91adb1e-103f-413b-945e-ea39571ca825-0'), HumanMessage(content='<|start_header_id|>player1<|end_header_id|>\\nMy name is Tsubasa.<|eot_id|>', additional_kwargs={}, response_metadata={}, id='177d1d57-3502-4979-96e3-3c9af71ec298')], 'context': AIMessage(content=['Empty DataFrame\\nColumns: [user_id, name, age, email, num_posts, num_likes, num_followers, num_following]\\nIndex: [].'], additional_kwargs={}, response_metadata={})}\n",
      "Context: content=['Empty DataFrame\\nColumns: [user_id, name, age, email, num_posts, num_likes, num_followers, num_following]\\nIndex: [].'] additional_kwargs={} response_metadata={}\n",
      "Generating response ...\n",
      "You, Tsubasa, are a character in the midst of the Vallaki's forced festivals of joy. You are not currently in the town square, but you are somehow connected to the scene.\n",
      "\n",
      "As the festival begins, the air is filled with the sounds of music and laughter. The townspeople are trying to put on a brave face, but the tension beneath the surface is palpable. You sense that something is off, and the atmosphere is thick with unease.\n",
      "\n",
      "You find yourself in a nearby tavern, the Red Griffin Inn. The fire is crackling, and the patrons are huddled in small groups, speaking in hushed tones. The bard in the corner raises her voice, singing a lively tune that seems to be a deliberate attempt to lift the spirits of the crowd.\n",
      "\n",
      "As you take a seat at the bar, the bard notices you and begins to sing a song that seems to be directed at you. The lyrics speak of a hero who has come to Vallaki, and the bard's eyes seem to lock onto yours, as if she knows you're the one she's singing about.\n",
      "\n",
      "The barkeep greets you with a friendly smile, offering you a mug of ale. What would you like to do?\n"
     ]
    }
   ],
   "source": [
    "input_message = \"<|start_header_id|>player1<|end_header_id|>\\nMy name is Tsubasa.<|eot_id|>\"\n",
    "\n",
    "input_state = {\n",
    "    \"name\": \"player_1\",\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=input_message)\n",
    "    ],\n",
    "    \"context\": \"\"\n",
    "}\n",
    "\n",
    "# for step in graph.stream(\n",
    "#     input_state,\n",
    "#     config=config,\n",
    "#     stream_mode=\"values\",\n",
    "# ):\n",
    "#     step[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "response = graph.invoke(input_state, config)\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d163be2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call request: [{'name': 'user', 'arguments': {'name': 'player1'}}]\n",
      "State: {'name': 'player_1', 'messages': [HumanMessage(content='<|start_header_id|>player_3<|end_header_id|>\\nCurrently I am level 1 wizard.\\nCan I cast meteor swarm?<|eot_id|>', additional_kwargs={}, response_metadata={}, id='489af465-4af6-4d01-8ce1-3ea2deac2dfe'), AIMessage(content=\"You can cast Meteor Swarm, but be aware that as a level 1 wizard, you do not have access to the spell. Meteor Swarm is a 9th-level evocation spell, which means you are still far from being able to cast it.\\n\\nAs you browse through the dusty tomes in the Baron's library, you overhear whispers of a mysterious gathering in the town square. The townspeople seem to be preparing for the Vallaki's forced festivals of joy, but there's an undercurrent of unease in the air. The Baron's guards are on high alert, and the air is thick with the smell of roasting meats and freshly baked bread.\\n\\nYou notice a group of traveling performers, including a juggler, a musician, and a fire dancer, setting up their acts near the town square. The crowd is growing, and the atmosphere is tense. What would you like to do?\", additional_kwargs={}, response_metadata={}, id='run--fe0dc82a-9e38-4a43-8f3b-74a4c8f06070-0'), HumanMessage(content='<|start_header_id|>player_3<|end_header_id|>\\nCan you give me infomation of name User3?<|eot_id|>', additional_kwargs={}, response_metadata={}, id='4ce0f2c8-810c-46cd-8835-aa26fcd339f5'), AIMessage(content=\"You are User_3, a level 1 wizard, with an age of 57 and an email address of user3@example.com. You have made 46 posts, received 8255 likes, and have 1651 followers. You are currently following 2 people.\\n\\nYou are in the midst of the Vallaki's forced festivals of joy in the town square. The tension is palpable, and the air is filled with the smell of roasting meats and freshly baked bread. The crowd is growing, and the traveling performers are setting up their acts.\\n\\nAs you observe the scene, you notice a group of guardsmen eyeing you suspiciously. They seem to be watching you with an air of curiosity, and you wonder if you've attracted their attention for some reason.\\n\\nThe festival's festivities are about to begin, and the Baron's voice booms through the speakers, announcing the start of the celebrations. The crowd erupts into cheers and applause, and the performers take their places. The juggler begins to juggle clubs, the musician starts to play a lively tune, and the fire dancer spins and leaps through the flames.\\n\\nWhat would you like to do next?\", additional_kwargs={}, response_metadata={}, id='run--b91adb1e-103f-413b-945e-ea39571ca825-0'), HumanMessage(content='<|start_header_id|>player1<|end_header_id|>\\nMy name is Tsubasa.<|eot_id|>', additional_kwargs={}, response_metadata={}, id='177d1d57-3502-4979-96e3-3c9af71ec298'), AIMessage(content=\"You, Tsubasa, are a character in the midst of the Vallaki's forced festivals of joy. You are not currently in the town square, but you are somehow connected to the scene.\\n\\nAs the festival begins, the air is filled with the sounds of music and laughter. The townspeople are trying to put on a brave face, but the tension beneath the surface is palpable. You sense that something is off, and the atmosphere is thick with unease.\\n\\nYou find yourself in a nearby tavern, the Red Griffin Inn. The fire is crackling, and the patrons are huddled in small groups, speaking in hushed tones. The bard in the corner raises her voice, singing a lively tune that seems to be a deliberate attempt to lift the spirits of the crowd.\\n\\nAs you take a seat at the bar, the bard notices you and begins to sing a song that seems to be directed at you. The lyrics speak of a hero who has come to Vallaki, and the bard's eyes seem to lock onto yours, as if she knows you're the one she's singing about.\\n\\nThe barkeep greets you with a friendly smile, offering you a mug of ale. What would you like to do?\", additional_kwargs={}, response_metadata={}, id='run--ee70d782-0af9-4f0c-ab1a-325c01181021-0'), HumanMessage(content='<|start_header_id|>player1<|end_header_id|>\\nhello, What is my name?<|eot_id|>', additional_kwargs={}, response_metadata={}, id='936cbd6b-3b8f-44a4-adca-a648bd1c1092')], 'context': AIMessage(content=['Empty DataFrame\\nColumns: [user_id, name, age, email, num_posts, num_likes, num_followers, num_following]\\nIndex: [].'], additional_kwargs={}, response_metadata={})}\n",
      "Context: content=['Empty DataFrame\\nColumns: [user_id, name, age, email, num_posts, num_likes, num_followers, num_following]\\nIndex: [].'] additional_kwargs={} response_metadata={}\n",
      "Generating response ...\n",
      "The bard's song comes to an abrupt end as she looks at you with a mixture of curiosity and concern. \"Ah, you're the one they're talking about, I suppose,\" she says, her voice low and cautious. \"My name is Elara, and I'm the bard for the Baron's festival. I was just... singing about the stranger who's come to Vallaki.\"\n",
      "\n",
      "She leans in closer, her voice taking on a conspiratorial tone. \"If you're the one I'm thinking of, you should be careful. The Baron's not one to be trifled with. He's... watching everyone closely, and anyone who attracts attention is of interest to him.\"\n",
      "\n",
      "Elara glances around the tavern, making sure no one is listening in. \"If you want to talk, I'm happy to share what I know. But be quick, and be careful.\"\n",
      "\n",
      "The patrons of the tavern seem to be watching you with interest, their conversations dying down as they sense the tension in the air. The barkeep clears his throat, reminding you that you're a guest in his establishment.\n",
      "\n",
      "What would you like to do?\n"
     ]
    }
   ],
   "source": [
    "input_message = \"<|start_header_id|>player1<|end_header_id|>\\nhello, What is my name?<|eot_id|>\"\n",
    "\n",
    "input_state = {\n",
    "    \"name\": \"player_1\",\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=input_message)\n",
    "    ],\n",
    "    \"context\": \"\"\n",
    "}\n",
    "\n",
    "# for step in graph.stream(\n",
    "#     input_state,\n",
    "#     config=config,\n",
    "#     stream_mode=\"values\",\n",
    "# ):\n",
    "#     step[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "response = graph.invoke(input_state, config)\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "be8fc7d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call request: [{'name': 'user', 'arguments': {'name': 'player1'}}]\n",
      "State: {'name': 'player_1', 'messages': [HumanMessage(content='<|start_header_id|>player_3<|end_header_id|>\\nCurrently I am level 1 wizard.\\nCan I cast meteor swarm?<|eot_id|>', additional_kwargs={}, response_metadata={}, id='489af465-4af6-4d01-8ce1-3ea2deac2dfe'), AIMessage(content=\"You can cast Meteor Swarm, but be aware that as a level 1 wizard, you do not have access to the spell. Meteor Swarm is a 9th-level evocation spell, which means you are still far from being able to cast it.\\n\\nAs you browse through the dusty tomes in the Baron's library, you overhear whispers of a mysterious gathering in the town square. The townspeople seem to be preparing for the Vallaki's forced festivals of joy, but there's an undercurrent of unease in the air. The Baron's guards are on high alert, and the air is thick with the smell of roasting meats and freshly baked bread.\\n\\nYou notice a group of traveling performers, including a juggler, a musician, and a fire dancer, setting up their acts near the town square. The crowd is growing, and the atmosphere is tense. What would you like to do?\", additional_kwargs={}, response_metadata={}, id='run--fe0dc82a-9e38-4a43-8f3b-74a4c8f06070-0'), HumanMessage(content='<|start_header_id|>player_3<|end_header_id|>\\nCan you give me infomation of name User3?<|eot_id|>', additional_kwargs={}, response_metadata={}, id='4ce0f2c8-810c-46cd-8835-aa26fcd339f5'), AIMessage(content=\"You are User_3, a level 1 wizard, with an age of 57 and an email address of user3@example.com. You have made 46 posts, received 8255 likes, and have 1651 followers. You are currently following 2 people.\\n\\nYou are in the midst of the Vallaki's forced festivals of joy in the town square. The tension is palpable, and the air is filled with the smell of roasting meats and freshly baked bread. The crowd is growing, and the traveling performers are setting up their acts.\\n\\nAs you observe the scene, you notice a group of guardsmen eyeing you suspiciously. They seem to be watching you with an air of curiosity, and you wonder if you've attracted their attention for some reason.\\n\\nThe festival's festivities are about to begin, and the Baron's voice booms through the speakers, announcing the start of the celebrations. The crowd erupts into cheers and applause, and the performers take their places. The juggler begins to juggle clubs, the musician starts to play a lively tune, and the fire dancer spins and leaps through the flames.\\n\\nWhat would you like to do next?\", additional_kwargs={}, response_metadata={}, id='run--b91adb1e-103f-413b-945e-ea39571ca825-0'), HumanMessage(content='<|start_header_id|>player1<|end_header_id|>\\nMy name is Tsubasa.<|eot_id|>', additional_kwargs={}, response_metadata={}, id='177d1d57-3502-4979-96e3-3c9af71ec298'), AIMessage(content=\"You, Tsubasa, are a character in the midst of the Vallaki's forced festivals of joy. You are not currently in the town square, but you are somehow connected to the scene.\\n\\nAs the festival begins, the air is filled with the sounds of music and laughter. The townspeople are trying to put on a brave face, but the tension beneath the surface is palpable. You sense that something is off, and the atmosphere is thick with unease.\\n\\nYou find yourself in a nearby tavern, the Red Griffin Inn. The fire is crackling, and the patrons are huddled in small groups, speaking in hushed tones. The bard in the corner raises her voice, singing a lively tune that seems to be a deliberate attempt to lift the spirits of the crowd.\\n\\nAs you take a seat at the bar, the bard notices you and begins to sing a song that seems to be directed at you. The lyrics speak of a hero who has come to Vallaki, and the bard's eyes seem to lock onto yours, as if she knows you're the one she's singing about.\\n\\nThe barkeep greets you with a friendly smile, offering you a mug of ale. What would you like to do?\", additional_kwargs={}, response_metadata={}, id='run--ee70d782-0af9-4f0c-ab1a-325c01181021-0'), HumanMessage(content='<|start_header_id|>player1<|end_header_id|>\\nhello, What is my name?<|eot_id|>', additional_kwargs={}, response_metadata={}, id='936cbd6b-3b8f-44a4-adca-a648bd1c1092'), AIMessage(content='The bard\\'s song comes to an abrupt end as she looks at you with a mixture of curiosity and concern. \"Ah, you\\'re the one they\\'re talking about, I suppose,\" she says, her voice low and cautious. \"My name is Elara, and I\\'m the bard for the Baron\\'s festival. I was just... singing about the stranger who\\'s come to Vallaki.\"\\n\\nShe leans in closer, her voice taking on a conspiratorial tone. \"If you\\'re the one I\\'m thinking of, you should be careful. The Baron\\'s not one to be trifled with. He\\'s... watching everyone closely, and anyone who attracts attention is of interest to him.\"\\n\\nElara glances around the tavern, making sure no one is listening in. \"If you want to talk, I\\'m happy to share what I know. But be quick, and be careful.\"\\n\\nThe patrons of the tavern seem to be watching you with interest, their conversations dying down as they sense the tension in the air. The barkeep clears his throat, reminding you that you\\'re a guest in his establishment.\\n\\nWhat would you like to do?', additional_kwargs={}, response_metadata={}, id='run--fc8f0209-1f54-42f0-87e8-c8f71f463553-0'), HumanMessage(content='<|start_header_id|>player1<|end_header_id|>\\nhello, What is my name?<|eot_id|>', additional_kwargs={}, response_metadata={}, id='a65788de-059b-4122-8dea-71d70f13bef2')], 'context': AIMessage(content=['Empty DataFrame\\nColumns: [user_id, name, age, email, num_posts, num_likes, num_followers, num_following]\\nIndex: [].'], additional_kwargs={}, response_metadata={})}\n",
      "Context: content=['Empty DataFrame\\nColumns: [user_id, name, age, email, num_posts, num_likes, num_followers, num_following]\\nIndex: [].'] additional_kwargs={} response_metadata={}\n",
      "Generating response ...\n",
      "Elara's expression turns apologetic, and she leans back, her voice dropping to a whisper. \"Ah, I'm so sorry, I didn't mean to pry. I just... you seem like someone who's been through a lot. But I don't know your name, do I?\"\n",
      "\n",
      "She pauses, studying your face, as if searching for some hidden clue. \"I'm just a bard, I don't usually get to know people's names, but... you seem different. If you want to share, I'm all ears.\"\n",
      "\n",
      "The patrons of the tavern seem to be watching the exchange with interest, their faces a mixture of curiosity and concern. The barkeep polishes a mug with a dirty rag, his eyes flicking between Elara and you.\n",
      "\n",
      "As the tension hangs in the air, a figure slips into the tavern, their eyes scanning the room before locking onto you. It's a young woman with a hood up, her face hidden in the shadows. She slips into the corner, ordering a drink without drawing attention to herself.\n",
      "\n",
      "What would you like to do?\n"
     ]
    }
   ],
   "source": [
    "input_message = \"<|start_header_id|>player1<|end_header_id|>\\nhello, What is my name?<|eot_id|>\"\n",
    "\n",
    "input_state = {\n",
    "    \"name\": \"player_1\",\n",
    "    \"messages\": [\n",
    "        HumanMessage(content=input_message)\n",
    "    ],\n",
    "    \"context\": \"\"\n",
    "}\n",
    "\n",
    "# for step in graph.stream(\n",
    "#     input_state,\n",
    "#     config=config,\n",
    "#     stream_mode=\"values\",\n",
    "# ):\n",
    "#     step[\"messages\"][-1].pretty_print()\n",
    "\n",
    "\n",
    "response = graph.invoke(input_state, config)\n",
    "\n",
    "print(response['messages'][-1].content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
