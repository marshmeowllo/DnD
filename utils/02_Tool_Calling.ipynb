{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ea2803",
   "metadata": {},
   "source": [
    "# Tool Calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29071199",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuaylong/miniconda3/envs/nlp/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: '__init_subclass__' (from 'transformers.agents.tools') is deprecated and will be removed from version '4.51.0'. Switch to smolagents instead, with the same functionalities and similar API (https://huggingface.co/docs/smolagents/index)\n",
      "  warnings.warn(warning_message, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import uuid\n",
    "import datetime\n",
    "import pprint\n",
    "import json\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, TransformersEngine, CodeAgent, BitsAndBytesConfig\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings, ChatHuggingFace\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain.tools import tool\n",
    "\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import render_text_description\n",
    "\n",
    "from typing import Annotated, Any, Dict, Optional, TypedDict, Union, List\n",
    "from lightning import Fabric\n",
    "from peft import LoraConfig, get_peft_model, PeftModelForCausalLM, PeftModel\n",
    "\n",
    "from IPython.display import display, Markdown, Image, SVG\n",
    "from os import walk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd806861",
   "metadata": {},
   "source": [
    "### Set mixed precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2463854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n"
     ]
    }
   ],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "fabric = Fabric(accelerator=\"cuda\", devices=1, precision=\"bf16-mixed\")\n",
    "device = fabric.device\n",
    "fabric.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "360d43f9",
   "metadata": {},
   "source": [
    "## RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209d3ce2",
   "metadata": {},
   "source": [
    "### Load Embedding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a4e12ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embed_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec305f39",
   "metadata": {},
   "source": [
    "### Load vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e38f0d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.load_local(\n",
    "    \"./faiss_spell_index\",\n",
    "    embeddings=embeddings,\n",
    "    allow_dangerous_deserialization=True\n",
    ")\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9397e417",
   "metadata": {},
   "source": [
    "## Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5e83247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The `load_in_4bit` and `load_in_8bit` arguments are deprecated and will be removed in the future versions. Please, pass a `BitsAndBytesConfig` object in `quantization_config` argument instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d9b52ed854407e902c245989a7ef31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"Salesforce/Llama-xLAM-2-8b-fc-r\"\n",
    "# model_name = \"NousResearch/Hermes-3-Llama-3.1-8B\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.bfloat16, load_in_4bit=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d564de6b",
   "metadata": {},
   "source": [
    "## Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20238b4",
   "metadata": {},
   "source": [
    "xLAM does not support native function calling, I referred to [this](https://python.langchain.com/docs/how_to/tools_prompting/) guide to parse the model's text output into JSON format.\n",
    "\n",
    "ref: [How does function calling work under the hood?](https://www.reddit.com/r/LangChain/comments/1d8y7mq/how_does_function_calling_work_under_the_hood/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dd857be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------\n",
      "get_weather\n",
      "Get the current weather for a city.\n",
      "Args:\n",
      "    city (str): The name of the city.\n",
      "\n",
      "Returns:\n",
      "    str: The current weather in the city.\n",
      "{'city': {'title': 'City', 'type': 'string'}}\n",
      "---------------------\n",
      "add\n",
      "Add two numbers.\n",
      "{'x': {'title': 'X', 'type': 'integer'}, 'y': {'title': 'Y', 'type': 'integer'}}\n",
      "---------------------\n",
      "multiply\n",
      "Multiply two numbers together.\n",
      "{'x': {'title': 'X', 'type': 'number'}, 'y': {'title': 'Y', 'type': 'number'}}\n",
      "---------------------\n",
      "spell_retrieve\n",
      "Retrieve information about dungeons and dragons spell.\n",
      "\n",
      "    Args:\n",
      "        query (str): The spell name to search for.\n",
      "\n",
      "    Returns:\n",
      "        str: The spell information.\n",
      "{'query': {'title': 'Query', 'type': 'string'}}\n",
      "---------------------\n",
      "user\n",
      "User infomation retreiver\n",
      "\n",
      "Args:\n",
      "    name (str): The name of user.\n",
      "\n",
      "Returns:\n",
      "    str: The user information.\n",
      "{'name': {'title': 'Name', 'type': 'string'}}\n"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def spell_retrieve(query: str) -> str:\n",
    "    \"\"\"Retrieve information about dungeons and dragons spell.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The spell name to search for.\n",
    "\n",
    "    Returns:\n",
    "        str: The spell information.\n",
    "    \"\"\"\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=3)\n",
    "\n",
    "    contents = \"\\n\\n\".join(\n",
    "        (f\"{doc.page_content}\")\n",
    "        for doc in retrieved_docs\n",
    "    )\n",
    "    \n",
    "    return contents\n",
    "\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the current weather for a city.\n",
    "    Args:\n",
    "        city (str): The name of the city.\n",
    "        \n",
    "    Returns:\n",
    "        str: The current weather in the city.\n",
    "    \"\"\"\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "\n",
    "@tool\n",
    "def add(x: int, y: int) -> int:\n",
    "    \"Add two numbers.\"\n",
    "    return x + y\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply two numbers together.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "@tool\n",
    "def user(name: str) -> str:\n",
    "    \"\"\"\n",
    "    User infomation retreiver\n",
    "\n",
    "    Args:\n",
    "        name (str): The name of user.\n",
    "\n",
    "    Returns:\n",
    "        str: The user information.\n",
    "    \"\"\"\n",
    "    return f'Hi, {name}.'\n",
    "\n",
    "tools = [\n",
    "    get_weather,\n",
    "    add,\n",
    "    multiply,\n",
    "    spell_retrieve,\n",
    "    user\n",
    "]\n",
    "\n",
    "for t in tools:\n",
    "    print(\"---------------------\")\n",
    "    print(t.name)\n",
    "    print(t.description)\n",
    "    print(t.args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3547895e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_weather(city: str) -> str - Get the current weather for a city.\n",
      "Args:\n",
      "    city (str): The name of the city.\n",
      "\n",
      "Returns:\n",
      "    str: The current weather in the city.\n",
      "add(x: int, y: int) -> int - Add two numbers.\n",
      "multiply(x: float, y: float) -> float - Multiply two numbers together.\n",
      "spell_retrieve(query: str) -> str - Retrieve information about dungeons and dragons spell.\n",
      "\n",
      "    Args:\n",
      "        query (str): The spell name to search for.\n",
      "\n",
      "    Returns:\n",
      "        str: The spell information.\n",
      "user(name: str) -> str - User infomation retreiver\n",
      "\n",
      "Args:\n",
      "    name (str): The name of user.\n",
      "\n",
      "Returns:\n",
      "    str: The user information.\n"
     ]
    }
   ],
   "source": [
    "rendered_tools = render_text_description(tools)\n",
    "print(rendered_tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "35db1d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    task=\"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=2048,\n",
    "    top_k=10,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "73140299",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToolCallRequest(TypedDict):\n",
    "    \"\"\"A typed dict that shows the inputs into the invoke_tool function.\"\"\"\n",
    "\n",
    "    name: str\n",
    "    arguments: Dict[str, Any]\n",
    "\n",
    "\n",
    "def invoke_tool(\n",
    "    tool_call_request: Union[ToolCallRequest, List[ToolCallRequest]], config: Optional[RunnableConfig] = None\n",
    "):\n",
    "    \"\"\"A function that we can use the perform a tool invocation.\n",
    "\n",
    "    Args:\n",
    "        tool_call_request: a dict that contains the keys name and arguments.\n",
    "            The name must match the name of a tool that exists.\n",
    "            The arguments are the arguments to that tool.\n",
    "        config: This is configuration information that LangChain uses that contains\n",
    "            things like callbacks, metadata, etc.See LCEL documentation about RunnableConfig.\n",
    "\n",
    "    Returns:\n",
    "        output from the requested tool\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Tool call request:\", tool_call_request)\n",
    "    \n",
    "    # Sometimes the model outputs a list of tool call requests, \n",
    "    # so I loop each tool call and append to list\n",
    "    \n",
    "    if isinstance(tool_call_request, list):\n",
    "        output = list()\n",
    "\n",
    "        for tool_call in tool_call_request:\n",
    "            tool_name_to_tool = {tool.name: tool for tool in tools}\n",
    "            name = tool_call[\"name\"]\n",
    "            requested_tool = tool_name_to_tool[name]\n",
    "            output.append(requested_tool.invoke(tool_call[\"arguments\"], config=config))\n",
    "        return output\n",
    "    \n",
    "    tool_name_to_tool = {tool.name: tool for tool in tools}\n",
    "    name = tool_call_request[\"name\"]\n",
    "    requested_tool = tool_name_to_tool[name]\n",
    "    return requested_tool.invoke(tool_call_request[\"arguments\"], config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d0f1bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool call request: [{'name': 'spell_retrieve', 'arguments': {'query': 'Absorb Elements'}}]\n",
      "0\t # Absorb Elements\n",
      "## Spell Name\n",
      "Absorb Elements  \n",
      "From Xanathar's Guide to Everything, page 150; and Elemental Evil Player's Companion, page 15.\n",
      "## Description\n",
      "*1st-level abjuration*\n",
      "* **Casting Time:** 1 reaction, which you take when you take acid, cold, fire, lightning, or thunder damage\n",
      "* **Range:** Self\n",
      "* **Components:** S\n",
      "* **Duration:** 1 round\n",
      "- **Casting Time:** 1 reaction, which you take when you take acid, cold, fire, lightning, or thunder damage\n",
      "**Casting Time:**\n",
      "- **Range:** Self\n",
      "**Range:**\n",
      "\n",
      "Disintegrate\n",
      "## Learned By\n",
      "* **Classes:** Artificer, Wizard\n",
      "* **Subclasses:** Cleric (*Peace Domain*), Cleric (*Protection Domain*), Fighter (*Eldritch Knight*), Paladin (*Oath of Redemption*), Rogue (*Arcane Trickster*)\n",
      "* **Backgrounds:** Izzet Engineer\n",
      "- **Classes:** Artificer, Wizard\n",
      "**Classes:**\n",
      "Artificer\n",
      "Wizard\n",
      "- **Subclasses:** Cleric (*Peace Domain*), Cleric (*Protection Domain*), Fighter (*Eldritch Knight*), Paladin (*Oath of Redemption*), Rogue (*Arcane Trickster*)\n",
      "**Subclasses:**\n",
      "*Peace Domain*\n",
      "\n",
      "# Disintegrate\n",
      "## Spell Name\n",
      "Disintegrate  \n",
      "From Player's Handbook, page 233.\n",
      "## Description\n",
      "*6th-level transmutation*\n",
      "* **Casting Time:** 1 action\n",
      "* **Range:** 60 feet\n",
      "* **Components:** V, S, M (a lodestone and a pinch of dust)\n",
      "* **Duration:** Instantaneous\n",
      "- **Casting Time:** 1 action\n",
      "**Casting Time:**\n",
      "- **Range:** 60 feet\n",
      "**Range:**\n",
      "- **Components:** V, S, M (a lodestone and a pinch of dust)\n",
      "**Components:**\n",
      "- **Duration:** Instantaneous\n",
      "**Duration:**\n"
     ]
    }
   ],
   "source": [
    "system_prompt = SystemMessage(f\"\"\"\\\n",
    "You are an assistant that has access to the following set of tools. \n",
    "Here are the names and descriptions for each tool:\n",
    "\n",
    "{rendered_tools}\n",
    "\n",
    "Given the user input, return the name and input of the tool to use. \n",
    "Return your response as a JSON blob with 'name' and 'arguments' keys.\n",
    "\n",
    "The `arguments` should be a dictionary, with keys corresponding \n",
    "to the argument names and the values corresponding to the requested values.\n",
    "\"\"\")\n",
    "\n",
    "chat = ChatHuggingFace(llm=llm, tokenizer=tokenizer)\n",
    "\n",
    "chain = chat | JsonOutputParser() | invoke_tool\n",
    "\n",
    "query = \"what is a Absorb Elements spell?\"\n",
    "\n",
    "messages = [system_prompt, HumanMessage(query)]\n",
    "\n",
    "response = chain.invoke(messages)\n",
    "\n",
    "if isinstance(response, list):\n",
    "    for idx, text in enumerate(response):\n",
    "        print(f'{idx}\\t {text}')\n",
    "else:\n",
    "    print(\"tool calling output:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "293c2901",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
