{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20ea2803",
   "metadata": {},
   "source": [
    "# RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "29071199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from typing import Any, Dict, Iterator, List, Optional, TypedDict\n",
    "\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter\n",
    "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings\n",
    "from langchain.storage import LocalFileStore\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain.embeddings import CacheBackedEmbeddings\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain.schema import AIMessage, HumanMessage\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langgraph.graph import MessagesState, StateGraph\n",
    "\n",
    "from lightning import Fabric\n",
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
    "from peft import LoraConfig, get_peft_model, PeftModelForCausalLM, PeftModel\n",
    "\n",
    "from IPython.display import display, Markdown, Image, SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd806861",
   "metadata": {},
   "source": [
    "### Set mixed precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2463854",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using bfloat16 Automatic Mixed Precision (AMP)\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4080') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n"
     ]
    }
   ],
   "source": [
    "fabric = Fabric(accelerator=\"cuda\", devices=1, precision=\"bf16-mixed\")\n",
    "device = fabric.device\n",
    "fabric.launch()\n",
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d4be07",
   "metadata": {},
   "source": [
    "### Text Splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6d25f4",
   "metadata": {},
   "source": [
    "ref: https://python.langchain.com/docs/how_to/markdown_header_metadata_splitter/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65d2cc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../datasets/spell_content/1st Level.txt', 'r') as file:\n",
    "    content = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ef0cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Spell Name\"),\n",
    "]\n",
    "\n",
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on, strip_headers=False)\n",
    "md_header_splits = markdown_splitter.split_text(content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28a8499",
   "metadata": {},
   "source": [
    "### Load Embedding Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1201ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(model_name=embed_model_name)\n",
    "vector_store = FAISS.from_documents(documents=md_header_splits, embedding=embeddings)\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d1fc9c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25784/3429349488.py:2: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  results = retriever.get_relevant_documents(query)\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# Detect Magic\n",
       "## Spell Name\n",
       "Detect Magic  \n",
       "From Player's Handbook, page 231.\n",
       "## Description\n",
       "*1st-level divination (ritual)*\n",
       "*1st-level divination (ritual)*\n",
       "* **Casting Time:** 1 action\n",
       "* **Range:** Self\n",
       "* **Components:** V, S\n",
       "* **Duration:** Concentration, up to 10 minutes\n",
       "- **Casting Time:** 1 action\n",
       "**Casting Time:**\n",
       "- **Range:** Self\n",
       "**Range:**\n",
       "- **Components:** V, S\n",
       "**Components:**\n",
       "- **Duration:** Concentration, up to 10 minutes\n",
       "**Duration:**\n",
       "For the duration, you sense the presence of magic within 30 feet of you. If you sense magic in this way, you can use your action to see a faint aura around any visible creature or object in the area that bears magic, and you learn its school of magic, if any.\n",
       "The spell can penetrate most barriers, but it is blocked by 1 foot of stone, 1 inch of common metal, a thin sheet of lead, or 3 feet of wood or dirt.\n",
       "## Learned By\n",
       "* **Classes:** Artificer, Bard, Cleric, Druid, Paladin, Ranger, Sorcerer, Wizard\n",
       "* **Subclasses:** Cleric (*Arcana Domain*), Fighter (*Eldritch Knight*), Fighter (*Monster Hunter*), Paladin (*Oath of the Watchers*), Rogue (*Arcane Trickster*), Sorcerer (*Aberrant Mind*), Sorcerer (*Divine Soul*), Wizard (*Theurgy*)\n",
       "* **Eldritch Invocations:** Eldritch Sight\n",
       "* **Races:** Firbolg, Mark of Detection Half-elf, Owlin (UA)\n",
       "* **Feats:** Artificer Initiate, Drow High Magic, Fey Touched, Magic Initiate, Quicksmithing, Ritual Caster, Strixhaven Initiate\n",
       "- **Classes:** Artificer, Bard, Cleric, Druid, Paladin, Ranger, Sorcerer, Wizard\n",
       "**Classes:**\n",
       "Artificer\n",
       "Bard\n",
       "Cleric\n",
       "Druid\n",
       "Paladin\n",
       "Ranger\n",
       "Sorcerer\n",
       "Wizard\n",
       "- **Subclasses:** Cleric (*Arcana Domain*), Fighter (*Eldritch Knight*), Fighter (*Monster Hunter*), Paladin (*Oath of the Watchers*), Rogue (*Arcane Trickster*), Sorcerer (*Aberrant Mind*), Sorcerer (*Divine Soul*), Wizard (*Theurgy*)\n",
       "**Subclasses:**\n",
       "*Arcana Domain*\n",
       "Arcana Domain\n",
       "*Eldritch Knight*\n",
       "Eldritch Knight\n",
       "*Monster Hunter*\n",
       "Monster Hunter\n",
       "*Oath of the Watchers*\n",
       "Oath of the Watchers\n",
       "*Arcane Trickster*\n",
       "Arcane Trickster\n",
       "*Aberrant Mind*\n",
       "Aberrant Mind\n",
       "*Divine Soul*\n",
       "Divine Soul\n",
       "*Theurgy*\n",
       "Theurgy\n",
       "- **Eldritch Invocations:** Eldritch Sight\n",
       "**Eldritch Invocations:**\n",
       "Eldritch Sight\n",
       "- **Races:** Firbolg, Mark of Detection Half-elf, Owlin (UA)\n",
       "**Races:**\n",
       "Firbolg\n",
       "Mark of Detection Half-elf\n",
       "Owlin (UA)\n",
       "- **Feats:** Artificer Initiate, Drow High Magic, Fey Touched, Magic Initiate, Quicksmithing, Ritual Caster, Strixhaven Initiate\n",
       "**Feats:**\n",
       "Artificer Initiate\n",
       "Drow High Magic\n",
       "Fey Touched\n",
       "Magic Initiate\n",
       "Quicksmithing\n",
       "Ritual Caster\n",
       "Strixhaven Initiate"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"give me Detect Magic spell?\"\n",
    "results = retriever.get_relevant_documents(query)\n",
    "\n",
    "display(Markdown(results[0].page_content))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4678f5c9",
   "metadata": {},
   "source": [
    "### Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b96474c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a84fbda6254fca971c6f4f6c2daf3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yuaylong/miniconda3/envs/nlp/lib/python3.12/site-packages/peft/tuners/tuners_utils.py:167: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n",
      "/home/yuaylong/miniconda3/envs/nlp/lib/python3.12/site-packages/peft/peft_model.py:569: UserWarning: Found missing adapter keys while loading the checkpoint: ['base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.0.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.1.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.2.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.3.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.4.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.5.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.6.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.7.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.8.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.9.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.10.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.11.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.12.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.13.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.14.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.15.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.16.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.17.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.18.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.19.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.20.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.21.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.22.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.23.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.24.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.25.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.26.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.27.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.28.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.29.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.30.self_attn.k_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.q_proj.lora_B.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.k_proj.lora_A.default.weight', 'base_model.model.base_model.model.model.layers.31.self_attn.k_proj.lora_B.default.weight'].\n",
      "  warnings.warn(warn_message)\n"
     ]
    }
   ],
   "source": [
    "model_name = \"meta-llama/Meta-Llama-3-8B-Instruct\"\n",
    "\n",
    "lora_config = LoraConfig(\n",
    "    r=16,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"q_proj\", \"k_proj\"],\n",
    "    lora_dropout=0.2,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\"\n",
    ")\n",
    "\n",
    "quant_config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True,\n",
    "    bnb_4bit_quant_type=\"nf4\",\n",
    "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "    bnb_4bit_use_double_quant=True\n",
    ")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.padding_side = \"right\"\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    quantization_config=quant_config,\n",
    "    )\n",
    "\n",
    "lora_model = get_peft_model(base_model, lora_config)\n",
    "\n",
    "model = PeftModelForCausalLM.from_pretrained(\n",
    "    lora_model, \n",
    "    \"../best\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    is_trainable=False\n",
    "    )\n",
    "\n",
    "model = model.eval()\n",
    "model.config.use_cache = True\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7476c376",
   "metadata": {},
   "source": [
    "#### Examples\n",
    "\n",
    "```python\n",
    "system = SystemMessage(\n",
    "        content=(\n",
    "            \"in a text-based adventure (Dungeons and Dragons).\\n\"\n",
    "            \"Your job is to narrate the adventure and respond to the player's actions.\\n\"\n",
    "            \"Use the following pieces of retrieved context to answer the question.\\n\"\n",
    "            \"If you don't know the answer, say that you don't know. If player break the game rule notice to player.\\n\"\n",
    "            \"answer concise.\"\n",
    "            \"\\n\\n\"\n",
    "            \"{docs_content}\"\n",
    "            \"When you anwser to player you must answer in proper markdown format. (heading, table, bold, italic, paragraph, blockquotes)\\n\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "player_messages = [\n",
    "    HumanMessage(content=\"<|start_header_id|>player1<|end_header_id|>\\nI draw my sword!<|eot_id|>\"),\n",
    "    HumanMessage(content=\"<|start_header_id|>player2<|end_header_id|>\\nI cast a fireball!<|eot_id|>\"),\n",
    "    HumanMessage(content=\"<|start_header_id|>player2<|end_header_id|>\\nwhat player 1 do<|eot_id|>\"),\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f45bc70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n",
      "The model 'PeftModelForCausalLM' is not supported for text-generation. Supported models are ['AriaTextForCausalLM', 'BambaForCausalLM', 'BartForCausalLM', 'BertLMHeadModel', 'BertGenerationDecoder', 'BigBirdForCausalLM', 'BigBirdPegasusForCausalLM', 'BioGptForCausalLM', 'BlenderbotForCausalLM', 'BlenderbotSmallForCausalLM', 'BloomForCausalLM', 'CamembertForCausalLM', 'LlamaForCausalLM', 'CodeGenForCausalLM', 'CohereForCausalLM', 'Cohere2ForCausalLM', 'CpmAntForCausalLM', 'CTRLLMHeadModel', 'Data2VecTextForCausalLM', 'DbrxForCausalLM', 'DeepseekV3ForCausalLM', 'DiffLlamaForCausalLM', 'ElectraForCausalLM', 'Emu3ForCausalLM', 'ErnieForCausalLM', 'FalconForCausalLM', 'FalconMambaForCausalLM', 'FuyuForCausalLM', 'GemmaForCausalLM', 'Gemma2ForCausalLM', 'Gemma3ForConditionalGeneration', 'Gemma3ForCausalLM', 'GitForCausalLM', 'GlmForCausalLM', 'Glm4ForCausalLM', 'GotOcr2ForConditionalGeneration', 'GPT2LMHeadModel', 'GPT2LMHeadModel', 'GPTBigCodeForCausalLM', 'GPTNeoForCausalLM', 'GPTNeoXForCausalLM', 'GPTNeoXJapaneseForCausalLM', 'GPTJForCausalLM', 'GraniteForCausalLM', 'GraniteMoeForCausalLM', 'GraniteMoeSharedForCausalLM', 'HeliumForCausalLM', 'JambaForCausalLM', 'JetMoeForCausalLM', 'LlamaForCausalLM', 'Llama4ForCausalLM', 'Llama4ForCausalLM', 'MambaForCausalLM', 'Mamba2ForCausalLM', 'MarianForCausalLM', 'MBartForCausalLM', 'MegaForCausalLM', 'MegatronBertForCausalLM', 'MistralForCausalLM', 'MixtralForCausalLM', 'MllamaForCausalLM', 'MoshiForCausalLM', 'MptForCausalLM', 'MusicgenForCausalLM', 'MusicgenMelodyForCausalLM', 'MvpForCausalLM', 'NemotronForCausalLM', 'OlmoForCausalLM', 'Olmo2ForCausalLM', 'OlmoeForCausalLM', 'OpenLlamaForCausalLM', 'OpenAIGPTLMHeadModel', 'OPTForCausalLM', 'PegasusForCausalLM', 'PersimmonForCausalLM', 'PhiForCausalLM', 'Phi3ForCausalLM', 'Phi4MultimodalForCausalLM', 'PhimoeForCausalLM', 'PLBartForCausalLM', 'ProphetNetForCausalLM', 'QDQBertLMHeadModel', 'Qwen2ForCausalLM', 'Qwen2MoeForCausalLM', 'Qwen3ForCausalLM', 'Qwen3MoeForCausalLM', 'RecurrentGemmaForCausalLM', 'ReformerModelWithLMHead', 'RemBertForCausalLM', 'RobertaForCausalLM', 'RobertaPreLayerNormForCausalLM', 'RoCBertForCausalLM', 'RoFormerForCausalLM', 'RwkvForCausalLM', 'Speech2Text2ForCausalLM', 'StableLmForCausalLM', 'Starcoder2ForCausalLM', 'TransfoXLLMHeadModel', 'TrOCRForCausalLM', 'WhisperForCausalLM', 'XGLMForCausalLM', 'XLMWithLMHeadModel', 'XLMProphetNetForCausalLM', 'XLMRobertaForCausalLM', 'XLMRobertaXLForCausalLM', 'XLNetLMHeadModel', 'XmodForCausalLM', 'ZambaForCausalLM', 'Zamba2ForCausalLM'].\n"
     ]
    }
   ],
   "source": [
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    return_full_text=False,\n",
    "    max_new_tokens=4096,\n",
    "    top_k=50,\n",
    "    temperature=0.1,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "terminators = [\n",
    "    tokenizer.eos_token_id,\n",
    "    tokenizer.convert_tokens_to_ids(\"<|eot_id|>\")\n",
    "]\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=pipe, model_kwargs = {'temperature': 0.9, \"torch_dtype\": torch.bfloat16})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "03c809c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(TypedDict):\n",
    "    question: str\n",
    "    context: List[Document]\n",
    "    answer: str\n",
    "\n",
    "\n",
    "def retrieve(state: State):\n",
    "    try:\n",
    "        retrieved_docs = vector_store.similarity_search(state[\"question\"], k=3)\n",
    "        return {\"context\": retrieved_docs}\n",
    "    except Exception as e:\n",
    "        return {\"context\": []}\n",
    "\n",
    "\n",
    "def generate(state: State):\n",
    "    # Join the retrieved document content to form context\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in state[\"context\"])\n",
    "\n",
    "    # If no relevant context was retrieved, handle it gracefully\n",
    "    if not docs_content:\n",
    "        return {\"answer\": \"Sorry, I don't have enough context to answer your question.\"}\n",
    "\n",
    "    # Prepare the system message for the model\n",
    "    system_message_content = (\n",
    "        \"<|start_header_id|>system<|end_header_id|>\\n\"\n",
    "        \"In a text-based adventure (Dungeons and Dragons), your job is to narrate the adventure \"\n",
    "        \"and respond to the player's actions.\\n\"\n",
    "        \"Use the following pieces of retrieved context to answer the question.\\n\"\n",
    "        \"If you don't know the answer, say that you don't know. If the player breaks the game rules, \"\n",
    "        \"notify the player.\\n\"\n",
    "        \"This is the retrieved context:\\n\\n\"\n",
    "        f\"{docs_content}\\n\\n\"\n",
    "        \"When you answer the player, you must respond in proper markdown format: heading, table, bold, italic, paragraph, blockquotes.\\n\"\n",
    "    )\n",
    "\n",
    "    # Create the system and human messages\n",
    "    system_message = SystemMessage(content=system_message_content)\n",
    "    messages = [system_message] + [HumanMessage(content=state[\"question\"])]\n",
    "\n",
    "    try:\n",
    "        # Join the content and invoke the model\n",
    "        response = llm.invoke(\"\\n\".join([msg.content for msg in messages]))\n",
    "        return {\"answer\": response}\n",
    "    except Exception as e:\n",
    "        # Handle errors in generation\n",
    "        return {\"answer\": \"An error occurred while generating the response.\"}\n",
    "\n",
    "# State Graph for managing retrieval and generation steps\n",
    "graph_builder = StateGraph(State).add_sequence([retrieve, generate])\n",
    "graph_builder.add_edge(START, \"retrieve\")\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "3fa147f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|start_header_id|>player1<|end_header_id|>\n",
      "How I obtain a Guiding Bolt.<|eot_id|>\n",
      "assistant\n",
      "\n",
      "**Obtaining Guiding Bolt**\n",
      "\n",
      "Guiding Bolt is a 1st-level evocation spell found in the Player's Handbook, page 248. To obtain this spell, you can choose to learn it as a Cleric, Druid, Paladin, Sorcerer, Warlock, or Wizard. Additionally, you can learn it as a Mage of Quandrix or a Strixhaven Initiate.\n",
      "\n",
      "As a Cleric, you can learn Guiding Bolt as part of your spellcasting abilities, as it is listed under the Cleric's spellcasting class features. Similarly, as a Druid, Paladin, Sorcerer, Warlock, or Wizard, you can learn Guiding Bolt as part of your spellcasting abilities, as it is listed under your respective class features.\n",
      "\n",
      "As a Mage of Quandrix or a Strixhaven Initiate, you can learn Guiding Bolt as part of your magical training, as it is listed under your respective backgrounds.\n",
      "\n",
      "Once you have obtained the spell, you can cast it using your spell slots, following the spell's casting time, range, components, and duration.\n"
     ]
    }
   ],
   "source": [
    "response = graph.invoke({\"question\": \"<|start_header_id|>player1<|end_header_id|>\\nHow I obtain a Guiding Bolt.<|eot_id|>\"})\n",
    "\n",
    "print(response['question'])\n",
    "print(response['answer'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
